import { aiContingencyService } from "./aiContingencyService";
import { supabase } from "@/lib/supabase";

interface CopyGenerationRequest {
  briefing: string;
  platform: string;
  copyType: string;
  tone?: string;
  target?: string;
  objective?: string;
  additionalContext?: string;
  userId?: string;
}

interface CopyGenerationResponse {
  content: string;
  provider: string;
  model: string;
  tokensUsed: number;
  success: boolean;
  error?: string;
}

interface AISettings {
  defaultProvider: string;
  defaultModel: string;
  temperature: number;
  maxTokens: number;
}

export class CopyGenerationService {
  private settings: AISettings | null = null;

  /**
   * Carrega as configura√ß√µes de IA do banco de dados
   */
  private async loadAISettings(): Promise<AISettings> {
    if (this.settings) {
      return this.settings;
    }

    try {
      console.log("üîç Carregando configura√ß√µes de IA do banco...");
      
      const { data, error } = await supabase
        .from("admin_llm_settings")
        .select(
          "default_provider, temperature, max_tokens, gemini_model, openai_model, anthropic_model, openrouter_model, kilocode_model"
        )
        .single();

      if (error) {
        console.error("‚ùå Erro ao carregar configura√ß√µes de IA:", error);
        
        // Fallback tempor√°rio para desenvolvimento
        console.warn("‚ö†Ô∏è Usando configura√ß√µes padr√£o de fallback");
        this.settings = {
          defaultProvider: "gemini",
          defaultModel: "gemini-2.0-flash-exp",
          temperature: 0.7,
          maxTokens: 1000,
        };
        return this.settings;
      }
      
      console.log("üìã Dados carregados do banco:", data);
      
      // Verificar se h√° dados v√°lidos
      if (!data || !data.default_provider) {
        console.warn("‚ö†Ô∏è Dados do banco inv√°lidos, usando configura√ß√µes padr√£o");
        this.settings = {
          defaultProvider: "gemini",
          defaultModel: "gemini-2.0-flash-exp",
          temperature: 0.7,
          maxTokens: 1000,
        };
        return this.settings;
      }

      // Mapear o modelo baseado no provedor padr√£o
      let defaultModel = "";
      let provider = data.default_provider;
      
      console.log(`üéØ Provedor configurado: ${provider}`);

      switch (provider) {
        case "openai":
          defaultModel = data.openai_model;
          break;
        case "anthropic":
          defaultModel = data.anthropic_model;
          break;
        case "gemini":
          defaultModel = data.gemini_model;
          break;
        case "openrouter":
          defaultModel = data.openrouter_model;
          break;
        case "kilocode":
          defaultModel = data.kilocode_model;
          break;
        default:
          console.error(`‚ùå Provedor padr√£o '${provider}' n√£o √© suportado`);
          // Fallback para Gemini se provedor n√£o √© suportado
          defaultModel = "gemini-2.0-flash-exp";
          provider = "gemini";
      }

      if (!defaultModel) {
        console.warn(`‚ö†Ô∏è Modelo n√£o configurado para '${provider}', usando padr√£o`);
        defaultModel = "gemini-2.0-flash-exp";
      }
      
      console.log(`ü§ñ Modelo selecionado: ${defaultModel}`);

      this.settings = {
        defaultProvider: provider,
        defaultModel,
        temperature: data.temperature || 0.7,
        maxTokens: data.max_tokens || 1000,
      };

      return this.settings;
    } catch (error) {
      console.error("Erro ao carregar configura√ß√µes de IA:", error);
      throw error;
    }
  }

  /**
   * Gera copy usando IA baseado nos par√¢metros fornecidos
   */
  async generateCopy(
    request: CopyGenerationRequest
  ): Promise<CopyGenerationResponse> {
    try {
      console.log("üöÄ Iniciando gera√ß√£o de copy...");
      console.log("Briefing:", request.briefing?.substring(0, 100) + "...");
      console.log("Plataforma:", request.platform);
      console.log("Tipo:", request.copyType);
      
      // Carregar configura√ß√µes de IA dinamicamente
      console.log("üîÑ Carregando configura√ß√µes de IA...");
      const aiSettings = await this.loadAISettings();

      console.log(
        `ü§ñ Gerando copy usando ${aiSettings.defaultProvider} com modelo ${aiSettings.defaultModel}`
      );

      // Construir prompt estruturado para gera√ß√£o de copy
      console.log("üìù Construindo prompt...");
      const prompt = this.buildPrompt(request);
      
      console.log("Prompt constru√≠do (primeiros 200 chars):", prompt.substring(0, 200) + "...");

      // Fazer requisi√ß√£o usando o servi√ßo de conting√™ncia de IA
      console.log("üîÑ Executando requisi√ß√£o de IA...");
      const response = await aiContingencyService.executeRequest(
        {
          prompt,
          maxTokens: aiSettings.maxTokens,
          temperature: aiSettings.temperature,
          userId: request.userId,
          context: "copy_generation",
        },
        aiSettings.defaultProvider
      ); // Usar o provedor configurado no banco

      console.log(
        `‚úÖ Copy gerada com sucesso! Provedor: ${response.provider}, Modelo: ${response.model}, Tokens: ${response.tokensUsed}`
      );

      return {
        content: response.content,
        provider: response.provider,
        model: response.model,
        tokensUsed: response.tokensUsed,
        success: response.success,
        error: response.error,
      };
    } catch (error) {
      console.error("Erro na gera√ß√£o de copy:", error);
      return {
        content: "",
        provider: "",
        model: "",
        tokensUsed: 0,
        success: false,
        error: error instanceof Error ? error.message : "Erro desconhecido",
      };
    }
  }

  /**
   * Constr√≥i prompt estruturado para gera√ß√£o de copy
   */
  private buildPrompt(request: CopyGenerationRequest): string {
    let prompt = `Voc√™ √© um especialista em copywriting e marketing digital. Crie uma copy persuasiva e engajante baseada nas seguintes especifica√ß√µes:

**BRIEFING:**
${request.briefing}

**PLATAFORMA:** ${request.platform}
**TIPO DE COPY:** ${request.copyType}`;

    if (request.tone) {
      prompt += `\n**TOM DE VOZ:** ${request.tone}`;
    }

    if (request.target) {
      prompt += `\n**P√öBLICO-ALVO:** ${request.target}`;
    }

    if (request.objective) {
      prompt += `\n**OBJETIVO:** ${request.objective}`;
    }

    if (request.additionalContext) {
      prompt += `\n**CONTEXTO ADICIONAL:** ${request.additionalContext}`;
    }

    prompt += `

**INSTRU√á√ïES:**
1. Crie uma copy otimizada especificamente para ${request.platform}
2. Use um tom ${request.tone || "adequado ao contexto"}
3. Inclua elementos visuais apropriados (emojis, quebras de linha, hashtags quando relevante)
4. Foque na convers√£o e engajamento
5. Mantenha o comprimento adequado para a plataforma
6. Inclua uma call-to-action clara
7. Use t√©cnicas de copywriting comprovadas

**FORMATO DA RESPOSTA:**
Retorne apenas a copy final, sem explica√ß√µes adicionais. A copy deve estar pronta para ser publicada diretamente na plataforma especificada.`;

    return prompt;
  }

  /**
   * Gera varia√ß√µes de uma copy existente
   */
  async generateVariations(
    originalCopy: string,
    count: number = 3,
    userId?: string
  ): Promise<CopyGenerationResponse[]> {
    const prompt = `Crie ${count} varia√ß√µes diferentes da seguinte copy, mantendo a ess√™ncia e objetivo, mas alterando a abordagem, palavras e estrutura:

COPY ORIGINAL:
${originalCopy}

INSTRU√á√ïES:
- Mantenha o mesmo objetivo e tom
- Varie a estrutura e palavras
- Mantenha emojis e hashtags relevantes
- Cada varia√ß√£o deve ser √∫nica e impactante

Retorne cada varia√ß√£o separada por "---" (tr√™s h√≠fens).`;

    try {
      // Carregar configura√ß√µes de IA dinamicamente
      const aiSettings = await this.loadAISettings();

      const response = await aiContingencyService.executeRequest(
        {
          prompt,
          maxTokens: Math.floor(aiSettings.maxTokens * 1.2), // Um pouco mais para m√∫ltiplas varia√ß√µes
          temperature: Math.min(aiSettings.temperature + 0.1, 1.0), // Aumentar criatividade
          userId,
          context: "copy_variations",
        },
        aiSettings.defaultProvider
      ); // Usar o provedor configurado

      // Dividir as varia√ß√µes
      const variations = response.content
        .split("---")
        .map((v) => v.trim())
        .filter((v) => v.length > 0);

      return variations.map((content) => ({
        content,
        provider: response.provider,
        model: response.model,
        tokensUsed: Math.floor(response.tokensUsed / variations.length),
        success: true,
      }));
    } catch (error) {
      console.error("Erro na gera√ß√£o de varia√ß√µes:", error);
      return [
        {
          content: "",
          provider: "",
          model: "",
          tokensUsed: 0,
          success: false,
          error: error instanceof Error ? error.message : "Erro desconhecido",
        },
      ];
    }
  }

  /**
   * Otimiza uma copy existente para melhor performance
   */
  async optimizeCopy(
    copy: string,
    platform: string,
    feedback?: string,
    userId?: string
  ): Promise<CopyGenerationResponse> {
    let prompt = `Otimize a seguinte copy para maximizar engajamento e convers√£o na plataforma ${platform}:

COPY ATUAL:
${copy}

PLATAFORMA: ${platform}`;

    if (feedback) {
      prompt += `\n\nFEEDBACK/PROBLEMAS IDENTIFICADOS:
${feedback}`;
    }

    prompt += `

INSTRU√á√ïES PARA OTIMIZA√á√ÉO:
1. Melhore o gancho inicial para capturar aten√ß√£o
2. Fortale√ßa a proposta de valor
3. Otimize a call-to-action
4. Ajuste para as melhores pr√°ticas da plataforma ${platform}
5. Melhore o flow e legibilidade
6. Adicione elementos de urg√™ncia/escassez se apropriado
7. Optimize hashtags e emojis

Retorne apenas a copy otimizada, pronta para publica√ß√£o.`;

    try {
      // Carregar configura√ß√µes de IA dinamicamente
      const aiSettings = await this.loadAISettings();

      const response = await aiContingencyService.executeRequest(
        {
          prompt,
          maxTokens: aiSettings.maxTokens,
          temperature: Math.max(aiSettings.temperature - 0.1, 0.1), // Reduzir criatividade para otimiza√ß√£o
          userId,
          context: "copy_optimization",
        },
        aiSettings.defaultProvider
      ); // Usar o provedor configurado

      return {
        content: response.content,
        provider: response.provider,
        model: response.model,
        tokensUsed: response.tokensUsed,
        success: response.success,
        error: response.error,
      };
    } catch (error) {
      console.error("Erro na otimiza√ß√£o de copy:", error);
      return {
        content: "",
        provider: "",
        model: "",
        tokensUsed: 0,
        success: false,
        error: error instanceof Error ? error.message : "Erro desconhecido",
      };
    }
  }

  /**
   * For√ßa o recarregamento das configura√ß√µes de IA
   */
  async reloadSettings(): Promise<void> {
    this.settings = null;
  }

  /**
   * Verifica se as configura√ß√µes de IA est√£o v√°lidas
   */
  async validateSettings(): Promise<{ valid: boolean; message: string }> {
    try {
      const settings = await this.loadAISettings();
      return {
        valid: true,
        message: `Configurado para usar ${settings.defaultProvider} com modelo ${settings.defaultModel}`,
      };
    } catch (error) {
      return {
        valid: false,
        message:
          error instanceof Error
            ? error.message
            : "Erro desconhecido ao validar configura√ß√µes",
      };
    }
  }
}

// Inst√¢ncia singleton do servi√ßo
export const copyGenerationService = new CopyGenerationService();
export default copyGenerationService;
