import { supabase } from "@/lib/supabase";

// Tipos para o sistema de conting√™ncia
interface AIProvider {
  key: string;
  name: string;
  active: boolean;
  apiKey: string;
  model: string;
}

interface ContingencySettings {
  contingencyEnabled: boolean;
  fallbackPriority: Record<string, number>;
  autoRetryEnabled: boolean;
  maxRetryAttempts: number;
  retryDelaySeconds: number;
}

interface AIRequest {
  prompt: string;
  model?: string;
  maxTokens?: number;
  temperature?: number;
  userId?: string;
  context?: string;
}

interface AIResponse {
  content: string;
  provider: string;
  model: string;
  tokensUsed: number;
  success: boolean;
  error?: string;
}

interface ContingencyLog {
  originalProvider: string;
  fallbackProvider: string;
  reason: string;
  timestamp: Date;
  userId?: string;
  requestId: string;
}

class AIContingencyService {
  private settings: ContingencySettings | null = null;
  private providers: AIProvider[] = [];

  constructor() {
    this.loadSettings();
  }

  /**
   * Carrega as configura√ß√µes de conting√™ncia do banco de dados
   */
  private async loadSettings(): Promise<void> {
    try {
      const { data, error } = await supabase
        .from("admin_llm_settings")
        .select("*")
        .limit(1);

      if (error) {
        console.error("Erro ao carregar configura√ß√µes de conting√™ncia:", error);
        return;
      }

      // Se n√£o h√° dados, criar configura√ß√µes padr√£o
      if (!data || data.length === 0) {
        console.warn("‚ö†Ô∏è Nenhuma configura√ß√£o encontrada no banco. Usando configura√ß√µes padr√£o.");
        
        this.settings = {
          contingencyEnabled: false,
          fallbackPriority: {"gemini": 1},
          autoRetryEnabled: true,
          maxRetryAttempts: 3,
          retryDelaySeconds: 5,
        };
        
        // Criar provedor padr√£o (Gemini com simula√ß√£o)
        this.providers = [
          {
            key: "gemini",
            name: "Google Gemini",
            active: true,
            apiKey: '', // Sem API key = simula√ß√£o
            model: 'gemini-2.0-flash-exp',
          }
        ];
        
        console.log("üëç Configura√ß√µes padr√£o criadas com simula√ß√£o Gemini");
        return;
      }

      const settingsData = data[0];
      if (settingsData) {
        this.settings = {
          contingencyEnabled: settingsData.contingency_enabled ?? false,
          fallbackPriority: settingsData.fallback_priority ?? {},
          autoRetryEnabled: settingsData.auto_retry_enabled ?? true,
          maxRetryAttempts: settingsData.max_retry_attempts ?? 3,
          retryDelaySeconds: settingsData.retry_delay_seconds ?? 5,
        };

        // Carregar provedores ativos
        console.log("üîÑ Carregando provedores de IA:", settingsData);
        
        this.providers = [
          {
            key: "openai",
            name: "OpenAI",
            active: settingsData?.openai_active || false,
            apiKey: settingsData?.openai_api_key || '',
            model: settingsData?.openai_model || 'gpt-4',
          },
          {
            key: "anthropic",
            name: "Claude (Anthropic)",
            active: settingsData?.anthropic_active || false,
            apiKey: settingsData?.anthropic_api_key || '',
            model: settingsData?.anthropic_model || 'claude-3-sonnet-20240229',
          },
          {
            key: "gemini",
            name: "Google Gemini",
            active: settingsData?.gemini_active ?? true, // Padr√£o ativo
            apiKey: settingsData?.gemini_api_key || '',
            model: settingsData?.gemini_model || 'gemini-2.0-flash-exp',
          },
          {
            key: "openrouter",
            name: "OpenRouter",
            active: settingsData?.openrouter_active || false,
            apiKey: settingsData?.openrouter_api_key || '',
            model: settingsData?.openrouter_model || 'openai/gpt-4',
          },
          {
            key: "kilocode",
            name: "Kilocode",
            active: settingsData?.kilocode_active || false,
            apiKey: settingsData?.kilocode_api_key || '',
            model: settingsData?.kilocode_model || 'kilocode-model',
          },
        ];
        
        console.log("üëç Provedores carregados:", this.providers.map(p => `${p.name}: ${p.active ? 'ativo' : 'inativo'}`));
      }
    } catch (error) {
      console.error("Erro ao carregar configura√ß√µes de conting√™ncia:", error);
    }
  }

  /**
   * Obt√©m provedores ordenados por prioridade (apenas os ativos)
   */
  private getProvidersByPriority(): AIProvider[] {
    if (!this.settings) return [];

    return this.providers
      .filter((provider) => provider.active) // Remover filtro de API key para permitir simula√ß√£o
      .sort((a, b) => {
        const priorityA = this.settings!.fallbackPriority[a.key] || 999;
        const priorityB = this.settings!.fallbackPriority[b.key] || 999;
        return priorityA - priorityB;
      });
  }

  /**
   * Faz uma requisi√ß√£o para um provedor espec√≠fico
   */
  private async makeRequest(
    provider: AIProvider,
    request: AIRequest
  ): Promise<AIResponse> {
    try {
      console.log(
        `ü§ñ Fazendo requisi√ß√£o REAL para ${provider.name} com modelo ${provider.model}`
      );

      // Implementar integra√ß√£o real baseada no provedor
      switch (provider.key) {
        case "gemini":
          return await this.makeGeminiRequest(provider, request);
        case "openai":
          return await this.makeOpenAIRequest(provider, request);
        case "anthropic":
          return await this.makeAnthropicRequest(provider, request);
        case "openrouter":
          return await this.makeOpenRouterRequest(provider, request);
        case "kilocode":
          return await this.makeKilocodeRequest(provider, request);
        default:
          throw new Error(`Provedor ${provider.key} n√£o implementado`);
      }
    } catch (error) {
      throw new Error(`Erro ao comunicar com ${provider.name}: ${error}`);
    }
  }

  /**
   * Faz requisi√ß√£o para Google Gemini
   */
  private async makeGeminiRequest(
    provider: AIProvider,
    request: AIRequest
  ): Promise<AIResponse> {
    // Verificar se API key est√° configurada
    if (!provider.apiKey || provider.apiKey.trim() === '') {
      console.warn(`‚ö†Ô∏è API key n√£o configurada para Gemini. Usando simula√ß√£o tempor√°ria.`);
      
      // Retornar resposta simulada para desenvolvimento
      return {
        content: `[SIMULA√á√ÉO GEMINI] Copy gerada para: ${request.prompt.substring(0, 50)}...\n\nüî• Esta √© uma copy simulada para demonstra√ß√£o.\n\nConfigure uma API key do Google Gemini nas configura√ß√µes para usar a IA real.`,
        provider: provider.key,
        model: provider.model,
        tokensUsed: Math.floor(Math.random() * 200) + 50,
        success: true,
      };
    }
    
    console.log(`üîÑ Fazendo requisi√ß√£o real para Google Gemini com modelo ${provider.model}`);
    
    const response = await fetch(
      `https://generativelanguage.googleapis.com/v1beta/models/${provider.model}:generateContent?key=${provider.apiKey}`,
      {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          contents: [
            {
              parts: [
                {
                  text: request.prompt,
                },
              ],
            },
          ],
          generationConfig: {
            temperature: request.temperature || 0.7,
            maxOutputTokens: request.maxTokens || 1000,
            topP: 0.8,
            topK: 10,
          },
        }),
      }
    );

    if (!response.ok) {
      const errorData = await response.text();
      throw new Error(
        `Erro na API do Gemini: ${response.status} - ${errorData}`
      );
    }

    const data = await response.json();

    if (
      !data.candidates ||
      !data.candidates[0] ||
      !data.candidates[0].content
    ) {
      throw new Error("Resposta inv√°lida da API do Gemini");
    }

    const content = data.candidates[0].content.parts[0].text;
    const tokensUsed = data.usageMetadata?.totalTokenCount || 0;

    return {
      content,
      provider: provider.key,
      model: provider.model,
      tokensUsed,
      success: true,
    };
  }

  /**
   * Faz requisi√ß√£o para OpenAI
   */
  private async makeOpenAIRequest(
    provider: AIProvider,
    request: AIRequest
  ): Promise<AIResponse> {
    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${provider.apiKey}`,
      },
      body: JSON.stringify({
        model: provider.model,
        messages: [
          {
            role: "user",
            content: request.prompt,
          },
        ],
        temperature: request.temperature || 0.7,
        max_tokens: request.maxTokens || 1000,
      }),
    });

    if (!response.ok) {
      const errorData = await response.text();
      throw new Error(
        `Erro na API da OpenAI: ${response.status} - ${errorData}`
      );
    }

    const data = await response.json();

    if (!data.choices || !data.choices[0] || !data.choices[0].message) {
      throw new Error("Resposta inv√°lida da API da OpenAI");
    }

    const content = data.choices[0].message.content;
    const tokensUsed = data.usage?.total_tokens || 0;

    return {
      content,
      provider: provider.key,
      model: provider.model,
      tokensUsed,
      success: true,
    };
  }

  /**
   * Faz requisi√ß√£o para Anthropic Claude
   */
  private async makeAnthropicRequest(
    provider: AIProvider,
    request: AIRequest
  ): Promise<AIResponse> {
    const response = await fetch("https://api.anthropic.com/v1/messages", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "x-api-key": provider.apiKey,
        "anthropic-version": "2023-06-01",
      },
      body: JSON.stringify({
        model: provider.model,
        messages: [
          {
            role: "user",
            content: request.prompt,
          },
        ],
        temperature: request.temperature || 0.7,
        max_tokens: request.maxTokens || 1000,
      }),
    });

    if (!response.ok) {
      const errorData = await response.text();
      throw new Error(
        `Erro na API da Anthropic: ${response.status} - ${errorData}`
      );
    }

    const data = await response.json();

    if (!data.content || !data.content[0] || !data.content[0].text) {
      throw new Error("Resposta inv√°lida da API da Anthropic");
    }

    const content = data.content[0].text;
    const tokensUsed = data.usage?.output_tokens || 0;

    return {
      content,
      provider: provider.key,
      model: provider.model,
      tokensUsed,
      success: true,
    };
  }

  /**
   * Faz requisi√ß√£o para OpenRouter
   */
  private async makeOpenRouterRequest(
    provider: AIProvider,
    request: AIRequest
  ): Promise<AIResponse> {
    const response = await fetch(
      "https://openrouter.ai/api/v1/chat/completions",
      {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${provider.apiKey}`,
          "HTTP-Referer": window.location.origin,
          "X-Title": "StorySpark",
        },
        body: JSON.stringify({
          model: provider.model,
          messages: [
            {
              role: "user",
              content: request.prompt,
            },
          ],
          temperature: request.temperature || 0.7,
          max_tokens: request.maxTokens || 1000,
        }),
      }
    );

    if (!response.ok) {
      const errorData = await response.text();
      throw new Error(
        `Erro na API do OpenRouter: ${response.status} - ${errorData}`
      );
    }

    const data = await response.json();

    if (!data.choices || !data.choices[0] || !data.choices[0].message) {
      throw new Error("Resposta inv√°lida da API do OpenRouter");
    }

    const content = data.choices[0].message.content;
    const tokensUsed = data.usage?.total_tokens || 0;

    return {
      content,
      provider: provider.key,
      model: provider.model,
      tokensUsed,
      success: true,
    };
  }

  /**
   * Faz requisi√ß√£o para Kilocode
   */
  private async makeKilocodeRequest(
    provider: AIProvider,
    request: AIRequest
  ): Promise<AIResponse> {
    // Implementar conforme a API da Kilocode quando dispon√≠vel
    // Por enquanto, usar simula√ß√£o
    console.warn("‚ö†Ô∏è Kilocode API n√£o implementada ainda, usando simula√ß√£o");

    return {
      content: `[SIMULA√á√ÉO KILOCODE] Copy gerada baseada em: ${request.prompt.substring(
        0,
        100
      )}...`,
      provider: provider.key,
      model: provider.model,
      tokensUsed: Math.floor(Math.random() * 500) + 100,
      success: true,
    };
  }

  /**
   * Registra um evento de conting√™ncia no log
   */
  private async logContingencyEvent(log: ContingencyLog): Promise<void> {
    try {
      const { error } = await supabase.from("ai_contingency_logs").insert({
        original_provider: log.originalProvider,
        fallback_provider: log.fallbackProvider,
        reason: log.reason,
        timestamp: log.timestamp.toISOString(),
        user_id: log.userId,
        request_id: log.requestId,
      });

      if (error) {
        console.error("Erro ao registrar log de conting√™ncia:", error);
      }
    } catch (error) {
      console.error("Erro ao registrar log de conting√™ncia:", error);
    }
  }

  /**
   * Aplica delay antes de tentar novamente
   */
  private async delay(seconds: number): Promise<void> {
    return new Promise((resolve) => setTimeout(resolve, seconds * 1000));
  }

  /**
   * Executa uma requisi√ß√£o de IA com sistema de conting√™ncia autom√°tica
   */
  async executeRequest(
    request: AIRequest,
    preferredProvider?: string
  ): Promise<AIResponse> {
    console.log("üöÄ ExecuteRequest iniciado:", { preferredProvider, prompt: request.prompt?.substring(0, 50) + '...' });
    
    // Garantir que as configura√ß√µes est√£o carregadas
    if (!this.settings) {
      console.log("üîÑ Carregando settings...");
      await this.loadSettings();
    }
    
    console.log("üìä Status ap√≥s loadSettings:", {
      settingsLoaded: !!this.settings,
      providersCount: this.providers.length,
      activeProviders: this.providers.filter(p => p.active).length
    });

    // Se conting√™ncia n√£o est√° habilitada, usar apenas o provedor preferido
    if (!this.settings?.contingencyEnabled) {
      const provider = this.providers.find(
        (p) => p.key === preferredProvider && p.active && p.apiKey
      );
      if (!provider) {
        throw new Error("Provedor especificado n√£o est√° dispon√≠vel");
      }
      return await this.makeRequest(provider, request);
    }

    const orderedProviders = this.getProvidersByPriority();

    if (orderedProviders.length === 0) {
      throw new Error("Nenhum provedor de IA est√° ativo");
    }

    // Se um provedor preferido foi especificado, tentar ele primeiro
    if (preferredProvider) {
      const preferredIndex = orderedProviders.findIndex(
        (p) => p.key === preferredProvider
      );
      if (preferredIndex > -1) {
        const [preferred] = orderedProviders.splice(preferredIndex, 1);
        orderedProviders.unshift(preferred);
      }
    }

    const requestId = Date.now().toString();
    let lastError: string = "";

    // Tentar cada provedor na ordem de prioridade
    for (let i = 0; i < orderedProviders.length; i++) {
      const provider = orderedProviders[i];
      let attempts = 0;
      const maxAttempts = this.settings.autoRetryEnabled
        ? this.settings.maxRetryAttempts
        : 1;

      // Tentar o provedor atual com retry se habilitado
      while (attempts < maxAttempts) {
        try {
          console.log(
            `Tentativa ${attempts + 1}/${maxAttempts} com ${provider.name}`
          );

          const response = await this.makeRequest(provider, request);

          // Se n√£o √© o primeiro provedor, registrar evento de conting√™ncia
          if (i > 0) {
            await this.logContingencyEvent({
              originalProvider: orderedProviders[0].key,
              fallbackProvider: provider.key,
              reason: lastError,
              timestamp: new Date(),
              userId: request.userId,
              requestId,
            });
          }

          return response;
        } catch (error) {
          attempts++;
          lastError = `${error}`;

          console.log(
            `Falha na tentativa ${attempts} com ${provider.name}: ${lastError}`
          );

          // Se n√£o √© a √∫ltima tentativa, aplicar delay
          if (attempts < maxAttempts) {
            await this.delay(this.settings.retryDelaySeconds);
          }
        }
      }

      console.log(
        `Provedor ${provider.name} falhou ap√≥s ${maxAttempts} tentativas. Tentando pr√≥ximo provedor...`
      );
    }

    // Se chegou aqui, todos os provedores falharam
    throw new Error(
      `Todos os provedores de IA falharam. √öltimo erro: ${lastError}`
    );
  }

  /**
   * Testa a conectividade de um provedor espec√≠fico
   */
  async testProvider(
    providerKey: string
  ): Promise<{ success: boolean; message: string }> {
    const provider = this.providers.find((p) => p.key === providerKey);

    if (!provider) {
      return { success: false, message: "Provedor n√£o encontrado" };
    }

    if (!provider.active) {
      return { success: false, message: "Provedor n√£o est√° ativo" };
    }

    if (!provider.apiKey) {
      return { success: false, message: "API Key n√£o configurada" };
    }

    try {
      const testRequest: AIRequest = {
        prompt: "Teste de conectividade",
        maxTokens: 10,
        temperature: 0.1,
      };

      await this.makeRequest(provider, testRequest);
      return { success: true, message: "Provedor funcionando corretamente" };
    } catch (error) {
      return { success: false, message: `Erro: ${error}` };
    }
  }

  /**
   * Obt√©m estat√≠sticas de conting√™ncia
   */
  async getContingencyStats(days: number = 7): Promise<{
    totalRequests: number;
    contingencyActivations: number;
    providerFailures: Record<string, number>;
    mostUsedFallback: string;
  }> {
    try {
      const since = new Date();
      since.setDate(since.getDate() - days);

      const { data, error } = await supabase
        .from("ai_contingency_logs")
        .select("*")
        .gte("timestamp", since.toISOString());

      if (error) {
        console.error("Erro ao obter estat√≠sticas de conting√™ncia:", error);
        return {
          totalRequests: 0,
          contingencyActivations: 0,
          providerFailures: {},
          mostUsedFallback: "",
        };
      }

      const providerFailures: Record<string, number> = {};
      const fallbackUsage: Record<string, number> = {};

      data.forEach((log) => {
        // Contar falhas por provedor original
        providerFailures[log.original_provider] =
          (providerFailures[log.original_provider] || 0) + 1;

        // Contar uso de fallbacks
        fallbackUsage[log.fallback_provider] =
          (fallbackUsage[log.fallback_provider] || 0) + 1;
      });

      const mostUsedFallback =
        Object.entries(fallbackUsage).sort(([, a], [, b]) => b - a)[0]?.[0] ||
        "";

      return {
        totalRequests: data.length, // Simplificado - idealmente viria de outra tabela
        contingencyActivations: data.length,
        providerFailures,
        mostUsedFallback,
      };
    } catch (error) {
      console.error("Erro ao obter estat√≠sticas de conting√™ncia:", error);
      return {
        totalRequests: 0,
        contingencyActivations: 0,
        providerFailures: {},
        mostUsedFallback: "",
      };
    }
  }

  /**
   * For√ßa o recarregamento das configura√ß√µes
   */
  async reloadSettings(): Promise<void> {
    await this.loadSettings();
  }
}

// Inst√¢ncia singleton do servi√ßo
export const aiContingencyService = new AIContingencyService();
export default aiContingencyService;
